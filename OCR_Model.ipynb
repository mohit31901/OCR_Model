{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9f5toG-1pK6f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.activations import relu, sigmoid, softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from tensorflow.keras import backend as K #Import the tensorflow.keras backend\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Reshape, Bidirectional, LSTM, Dense, Activation, Lambda, BatchNormalization, Dropout, LayerNormalization\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VZNrlfbMrpTj"
   },
   "outputs": [],
   "source": [
    "with open('C:\\AI Models\\OCR_Model\\Dataset\\words_new.txt') as f:\n",
    "    contents = f.readlines()\n",
    "\n",
    "lines = [line.strip() for line in contents][18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1729326582586,
     "user": {
      "displayName": "Harshvardhan Gupta",
      "userId": "10328168051463798203"
     },
     "user_tz": -330
    },
    "id": "v1gPkWlysZV_",
    "outputId": "084063b0-71fa-449d-927a-1f02b913d17e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz 78\n"
     ]
    }
   ],
   "source": [
    "max_label_len = 0\n",
    "\n",
    "char_list = \"!\\\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "print(char_list, len(char_list))\n",
    "\n",
    "def encode_to_labels(txt):\n",
    "    # encoding each output word into digits\n",
    "    dig_lst = []\n",
    "    for index, chara in enumerate(txt):\n",
    "        dig_lst.append(char_list.index(chara))\n",
    "\n",
    "    return dig_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iyYY0nwHsd5K"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "RECORDS_COUNT = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DyPDFpHpsgIY"
   },
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "train_input_length = []\n",
    "train_label_length = []\n",
    "train_original_text = []\n",
    "\n",
    "valid_images = []\n",
    "valid_labels = []\n",
    "valid_input_length = []\n",
    "valid_label_length = []\n",
    "valid_original_text = []\n",
    "\n",
    "inputs_length = []\n",
    "labels_length = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "m7_2WmflskZX"
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    \"\"\"\n",
    "    Converts image to shape (32, 128, 1) & normalize\n",
    "    \"\"\"\n",
    "    w, h = img.shape\n",
    "    new_w = 32\n",
    "    new_h = int(h * (new_w / w))\n",
    "    img = cv2.resize(img, (new_h, new_w))\n",
    "    w, h = img.shape\n",
    "\n",
    "    img = img.astype('float32')\n",
    "\n",
    "    # Converts each to (32, 128, 1)\n",
    "    if w < 32:\n",
    "        add_zeros = np.full((32-w, h), 255)\n",
    "        img = np.concatenate((img, add_zeros))\n",
    "        w, h = img.shape\n",
    "\n",
    "    if h < 128:\n",
    "        add_zeros = np.full((w, 128-h), 255)\n",
    "        img = np.concatenate((img, add_zeros), axis=1)\n",
    "        w, h = img.shape\n",
    "\n",
    "    if h > 128 or w > 32:\n",
    "        dim = (128,32)\n",
    "        img = cv2.resize(img, dim)\n",
    "\n",
    "    img = cv2.subtract(255, img)\n",
    "\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "\n",
    "    # # Normalize\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2JpMJAXBswNq"
   },
   "outputs": [],
   "source": [
    "for index, line in enumerate(lines):\n",
    "    splits = line.split(' ')\n",
    "    status = splits[1]\n",
    "\n",
    "    if status == 'ok':\n",
    "        word_id = splits[0]\n",
    "        word = \"\".join(splits[8:])\n",
    "\n",
    "        splits_id = word_id.split('-')\n",
    "        filepath = 'C:\\AI Models\\OCR_Model\\Dataset\\iam_words\\words\\{}\\{}-{}\\{}.png'.format(splits_id[0], splits_id[0],  splits_id[1], word_id)\n",
    "\n",
    "        # process image\n",
    "        img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "        try:\n",
    "            img = process_image(img)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # process label\n",
    "        try:\n",
    "            label = encode_to_labels(word)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if index % 10 == 0:\n",
    "            valid_images.append(img)\n",
    "            valid_labels.append(label)\n",
    "            valid_input_length.append(31)\n",
    "            valid_label_length.append(len(word))\n",
    "            valid_original_text.append(word)\n",
    "        else:\n",
    "            train_images.append(img)\n",
    "            train_labels.append(label)\n",
    "            train_input_length.append(31)\n",
    "            train_label_length.append(len(word))\n",
    "            train_original_text.append(word)\n",
    "\n",
    "        if len(word) > max_label_len:\n",
    "            max_label_len = len(word)\n",
    "\n",
    "    if index >= RECORDS_COUNT:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "executionInfo": {
     "elapsed": 989,
     "status": "ok",
     "timestamp": 1729326639968,
     "user": {
      "displayName": "Harshvardhan Gupta",
      "userId": "10328168051463798203"
     },
     "user_tz": -330
    },
    "id": "6kGlYDvctOzt",
    "outputId": "1b383e3a-281e-48ca-ec86-9f0c80524027"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # Imports the matplotlib library\n",
    "\n",
    "plt.imshow(train_images[647], cmap='gray') # Uses matplotlib to display the image. Use cmap='gray' for grayscale images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I3LFTVw_ta9_"
   },
   "outputs": [],
   "source": [
    "train_padded_label = pad_sequences(train_labels,\n",
    "                             maxlen=max_label_len,\n",
    "                             padding='post',\n",
    "                             value=len(char_list))\n",
    "\n",
    "valid_padded_label = pad_sequences(valid_labels,\n",
    "                             maxlen=max_label_len,\n",
    "                             padding='post',\n",
    "                             value=len(char_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1729326644169,
     "user": {
      "displayName": "Harshvardhan Gupta",
      "userId": "10328168051463798203"
     },
     "user_tz": -330
    },
    "id": "pY1rtzvqtoM5",
    "outputId": "762664c0-c504-4615-8286-d37bb13e80bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67, 69, 66, 67, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_padded_label[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1729326644596,
     "user": {
      "displayName": "Harshvardhan Gupta",
      "userId": "10328168051463798203"
     },
     "user_tz": -330
    },
    "id": "wBE6SFuUtsFT",
    "outputId": "83f4557b-2a1c-4452-b260-0dc48eb1547b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23761, 17), (2644, 17))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded_label.shape, valid_padded_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i-oIAM86tyFh"
   },
   "outputs": [],
   "source": [
    "train_images = np.asarray(train_images)\n",
    "train_input_length = np.asarray(train_input_length)\n",
    "train_label_length = np.asarray(train_label_length)\n",
    "\n",
    "valid_images = np.asarray(valid_images)\n",
    "valid_input_length = np.asarray(valid_input_length)\n",
    "valid_label_length = np.asarray(valid_label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1729326647289,
     "user": {
      "displayName": "Harshvardhan Gupta",
      "userId": "10328168051463798203"
     },
     "user_tz": -330
    },
    "id": "7C5uU8SLt0Y2",
    "outputId": "1a0b97a2-9546-4752-852a-5ecdc9e06696"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23761, 32, 128, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Yyt3apvEyuLx"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nFb5ZG4it5D_"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # CNN layers\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 1))(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 1))(x)\n",
    "    \n",
    "    # Reshape for RNN\n",
    "    x = layers.Reshape((-1, x.shape[-1]))(x)\n",
    "\n",
    "\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True, dropout=0.2))(x)\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True, dropout=0.3))(x)\n",
    "\n",
    "    \n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OB6W7kG5oyBV"
   },
   "outputs": [],
   "source": [
    "input_shape = (32, 128, 1)\n",
    "num_classes = len(char_list) + 1  # +1 for CTC blank\n",
    "model = create_model(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NmIn8ifLo0Mu"
   },
   "outputs": [],
   "source": [
    "# CTC loss function\n",
    "def ctc_loss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    return keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1729326702029,
     "user": {
      "displayName": "Harshvardhan Gupta",
      "userId": "10328168051463798203"
     },
     "user_tz": -330
    },
    "id": "cZm5qFhk2vmh",
    "outputId": "f2dbbec0-8627-4314-c523-f5df612bc87c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 128, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 128, 64)       640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 64, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 64, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 32, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 32, 256)        295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 32, 256)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 32, 512)        1180160   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 4, 32, 512)       2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 4, 32, 512)        2359808   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4, 32, 512)       2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 32, 512)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 512)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64, 512)          1574912   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64, 512)          1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 64, 512)          1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64, 79)            40527     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,678,991\n",
      "Trainable params: 8,676,943\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "id": "VW_7yyUTlHFu"
   },
   "outputs": [],
   "source": [
    "class AccuracyCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data, char_list, max_label_len):\n",
    "        super(AccuracyCallback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.char_list = char_list\n",
    "        self.max_label_len = max_label_len\n",
    "\n",
    "    def calculate_cer(self, ground_truth, predicted):\n",
    "        \"\"\"Calculates the Character Error Rate (CER).\"\"\"\n",
    "        edit_distance = Levenshtein.distance(ground_truth, predicted)\n",
    "        cer = edit_distance / len(ground_truth)\n",
    "        return cer\n",
    "\n",
    "    def calculate_wer(self, ground_truth, predicted):\n",
    "        \"\"\"Calculates the Word Error Rate (WER).\"\"\"\n",
    "        ground_truth_words = ground_truth.split()\n",
    "        predicted_words = predicted.split()\n",
    "        edit_distance = Levenshtein.distance(ground_truth_words, predicted_words)\n",
    "        wer = edit_distance / len(ground_truth_words)\n",
    "        return wer\n",
    "\n",
    "    def decode_predictions(self, predictions):\n",
    "        \"\"\"Decodes predictions using CTC decoding.\"\"\"\n",
    "        input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n",
    "        results = keras.backend.ctc_decode(predictions,\n",
    "                                           input_length=input_len,\n",
    "                                           greedy=True)[0][0]\n",
    "        decoded_texts = []\n",
    "        for result in results:\n",
    "            decoded_text = ''.join([self.char_list[int(i)] for i in result if int(i) != -1])\n",
    "            decoded_texts.append(decoded_text)\n",
    "        return decoded_texts\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_val, y_val = self.validation_data\n",
    "        predictions = self.model.predict(x_val)\n",
    "        decoded_texts = self.decode_predictions(predictions)\n",
    "\n",
    "        total_cer = 0\n",
    "        total_wer = 0\n",
    "        num_samples = len(decoded_texts)\n",
    "\n",
    "        # Prepare validation ground truth texts\n",
    "        y_val_texts = []\n",
    "        for y in y_val:\n",
    "          text = ''.join([self.char_list[int(i)] for i in y if int(i) != len(self.char_list)])\n",
    "          y_val_texts.append(text)\n",
    "\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            cer = self.calculate_cer(y_val_texts[i], decoded_texts[i])\n",
    "            wer = self.calculate_wer(y_val_texts[i], decoded_texts[i])\n",
    "            total_cer += cer\n",
    "            total_wer += wer\n",
    "\n",
    "        avg_cer = total_cer / num_samples\n",
    "        avg_wer = total_wer / num_samples\n",
    "\n",
    "        print(f\"-Character Acc: {((1-avg_cer)*100):.4f}% -Word Acc: {((1-avg_wer)*100):.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "id": "_PjOjfJAlKM7"
   },
   "outputs": [],
   "source": [
    "accuracy_callback = AccuracyCallback(validation_data=(valid_images, valid_padded_label), char_list=char_list, max_label_len=max_label_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "id": "Li3BHi_apAEk"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=ctc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2505813,
     "status": "ok",
     "timestamp": 1729329238126,
     "user": {
      "displayName": "Harshvardhan Gupta",
      "userId": "10328168051463798203"
     },
     "user_tz": -330
    },
    "id": "u3TeC7VJpA_7",
    "outputId": "7220babf-8ce7-43b2-9102-414545210d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "83/83 [==============================] - 3s 21ms/step\n",
      "-Character Acc: 31.2033% -Word Acc: 17.7005%\n",
      "743/743 [==============================] - 108s 138ms/step - loss: 13.7821 - val_loss: 11.8212\n",
      "Epoch 2/25\n",
      "83/83 [==============================] - 2s 21ms/step\n",
      "-Character Acc: 60.7458% -Word Acc: 33.3585%\n",
      "743/743 [==============================] - 95s 128ms/step - loss: 8.7621 - val_loss: 6.9446\n",
      "Epoch 3/25\n",
      "83/83 [==============================] - 2s 21ms/step\n",
      "-Character Acc: 77.6515% -Word Acc: 48.2980%\n",
      "743/743 [==============================] - 95s 128ms/step - loss: 5.0747 - val_loss: 3.9783\n",
      "Epoch 4/25\n",
      "83/83 [==============================] - 2s 21ms/step\n",
      "-Character Acc: 81.7637% -Word Acc: 55.4085%\n",
      "743/743 [==============================] - 95s 128ms/step - loss: 3.2660 - val_loss: 3.2761\n",
      "Epoch 5/25\n",
      "83/83 [==============================] - 2s 21ms/step\n",
      "-Character Acc: 86.3825% -Word Acc: 61.9516%\n",
      "743/743 [==============================] - 98s 132ms/step - loss: 2.4476 - val_loss: 2.5262\n",
      "Epoch 6/25\n",
      "83/83 [==============================] - 2s 21ms/step\n",
      "-Character Acc: 86.1840% -Word Acc: 61.8759%\n",
      "743/743 [==============================] - 95s 128ms/step - loss: 1.8957 - val_loss: 2.5766\n",
      "Epoch 7/25\n",
      "83/83 [==============================] - 2s 22ms/step\n",
      "-Character Acc: 87.2725% -Word Acc: 64.5613%\n",
      "743/743 [==============================] - 96s 130ms/step - loss: 1.5618 - val_loss: 2.2969\n",
      "Epoch 8/25\n",
      "83/83 [==============================] - 2s 21ms/step\n",
      "-Character Acc: 88.4748% -Word Acc: 67.4735%\n",
      "743/743 [==============================] - 96s 130ms/step - loss: 1.2757 - val_loss: 2.1208\n",
      "Epoch 9/25\n",
      "83/83 [==============================] - 2s 22ms/step\n",
      "-Character Acc: 88.5907% -Word Acc: 68.8729%\n",
      "743/743 [==============================] - 98s 131ms/step - loss: 1.0632 - val_loss: 2.1727\n",
      "Epoch 10/25\n",
      "83/83 [==============================] - 2s 22ms/step\n",
      "-Character Acc: 88.9464% -Word Acc: 68.8351%\n",
      "743/743 [==============================] - 100s 135ms/step - loss: 0.9246 - val_loss: 2.0972\n",
      "Epoch 11/25\n",
      "83/83 [==============================] - 2s 21ms/step\n",
      "-Character Acc: 89.3284% -Word Acc: 69.7806%\n",
      "743/743 [==============================] - 96s 129ms/step - loss: 0.7733 - val_loss: 2.1659\n",
      "Epoch 12/25\n",
      "83/83 [==============================] - 2s 21ms/step\n",
      "-Character Acc: 89.3179% -Word Acc: 70.0454%\n",
      "743/743 [==============================] - 96s 129ms/step - loss: 0.6820 - val_loss: 2.1635\n",
      "Epoch 13/25\n",
      "83/83 [==============================] - 2s 21ms/step\n",
      "-Character Acc: 89.4124% -Word Acc: 70.8018%\n",
      "743/743 [==============================] - 95s 128ms/step - loss: 0.6072 - val_loss: 2.1779\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=train_images,\n",
    "    y=train_padded_label,\n",
    "    validation_data=(valid_images, valid_padded_label),\n",
    "    batch_size=32,\n",
    "    epochs=25,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            \"best_model.keras\",\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\"\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            patience=3,\n",
    "            monitor=\"val_loss\"\n",
    "        ),\n",
    "        accuracy_callback  # Add the AccuracyCallback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "id": "5m6slCdppgud"
   },
   "outputs": [],
   "source": [
    "# Save the model in SavedModel format\n",
    "model.save('ocr_model_saved.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('C:\\AI Models\\OCR_Model\\ocr_model_saved.keras', custom_objects={'ctc_loss': ctc_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=r'C:\\AI Models\\OCR_Model\\test-image.png'\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "img = process_image(img)\n",
    "\n",
    "pic = np.asarray(img)\n",
    "plt.imshow(pic, cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "print(' ')\n",
    "\n",
    "img = np.expand_dims(img, axis=0)\n",
    "prediction = loaded_model.predict(img)\n",
    "input_len = np.ones(prediction.shape[0]) * prediction.shape[1]\n",
    "results = keras.backend.ctc_decode(prediction,\n",
    "                                    input_length=input_len,\n",
    "                                    greedy=True)[0][0]\n",
    "\n",
    "output_text = []\n",
    "for result in results:\n",
    "    result = ''.join([char_list[int(i)] for i in result if int(i) != -1])\n",
    "    output_text.append(result)\n",
    "\n",
    "predicted_text=output_text[0]\n",
    "print(f\"Predicted text: {predicted_text}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
